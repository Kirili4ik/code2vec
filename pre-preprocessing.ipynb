{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_block</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60221</th>\n",
       "      <td>df_annotations = pd.DataFrame(train_annotation...</td>\n",
       "      <td>converting json to required csv format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101346</th>\n",
       "      <td>'''Count total groups in variable Ticket.'''\\n...</td>\n",
       "      <td>findings as expected name contains strings tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168819</th>\n",
       "      <td>\\nretail_mv = retail.groupby(['CustomerID']).a...</td>\n",
       "      <td>['lets look at amount spend per customer reven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               code_block  \\\n",
       "60221   df_annotations = pd.DataFrame(train_annotation...   \n",
       "101346  '''Count total groups in variable Ticket.'''\\n...   \n",
       "168819  \\nretail_mv = retail.groupby(['CustomerID']).a...   \n",
       "\n",
       "                                                      tag  \n",
       "60221              converting json to required csv format  \n",
       "101346  findings as expected name contains strings tha...  \n",
       "168819  ['lets look at amount spend per customer reven...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('code_blocks_final_clean.csv')\n",
    "data = data.drop(columns='Unnamed: 0', axis=1)\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128808"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tag'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221803, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление стоп-слов, стемминг, оставляем по одному комментарию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kirill/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/kirill/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kirill/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/kirill/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import download\n",
    "download('stopwords')\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_wr = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматайзер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kirill be play with fire'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(lemmatizer, sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "# example\n",
    "lemmatize_sentence(wnl, 'kirill is playing with fire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут из нескольких комментариев выбирается самый короткий (обосновано тем, что тогда он с большей вероятностью встречается часто == больше похож на метку). Отсекаются пробелы и всякие пустые метки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clear_tag(tag):\n",
    "    ready_tag = tag.replace('_', ' ')\n",
    "    ready_tag = re.sub('[^A-Za-z0-9 ]+', '', ready_tag)\n",
    "    ready_tag = ready_tag.strip()                    # removes spaces in the start and in the end\n",
    "    ready_tag = ready_tag.replace(' ', '_')\n",
    "    return ready_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "all_to_del = set(['', \"['']\", ' ', '  ', \"[' ']\", '        ', '     ', '    ', '   ', \"['', ' ']\", '       ', '      ', \\\n",
    "             '             ', '         ', '          ', \"']\",\\\n",
    "                 \"['   \", \"['\", \"[' \", \"['  \", \"['    \", \"['    \"])\n",
    "rows_to_del = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221803/221803 [00:53<00:00, 4167.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(data.shape[0])):\n",
    "    my_string = data.loc[i, 'tag']\n",
    "    \n",
    "    if (my_string is not np.nan) and my_string is not None:\n",
    "        \n",
    "        min_len = len(data.loc[i, 'tag']) + 10\n",
    "        min_el = None\n",
    "        s = set(list(map(str, my_string.split(\"', '\"))))\n",
    "        \n",
    "        for el in s:\n",
    "            \n",
    "            # getting rid of punctuation, spaces, adding \"_\"\n",
    "            el = clear_tag(el)\n",
    "            \n",
    "            if el not in all_to_del and el is not None and len(el) < 100:\n",
    "                \n",
    "                # getting rid of stop words\n",
    "                el = [w.lower() for w in el.split('_') if w.lower() not in st_wr]\n",
    "                el = '_'.join(el)\n",
    "                \n",
    "                # stemming \n",
    "                el = stemmer.stem(el)\n",
    "                \n",
    "                # lemmatizing\n",
    "                # el = lemmatize_sentence(wnl, el)\n",
    "                \n",
    "                if len(el) < min_len:\n",
    "                    min_len = len(el)\n",
    "                    min_el = el\n",
    "\n",
    "        if min_el is not None:\n",
    "            data.loc[i, 'tag'] = min_el\n",
    "        else:\n",
    "            rows_to_del.append(i)\n",
    "    else:\n",
    "        rows_to_del.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221803, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178782, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(rows_to_del)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "data.drop(columns=['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление пустых меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['tag'] != '']\n",
    "data = data[data['tag'] != '_']\n",
    "data = data[data['tag'] != '__']\n",
    "data = data[data['tag'] != '___']\n",
    "data = data[data['tag'] != '____']\n",
    "data = data[data['tag'] != '_____']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оставим самые популярные метки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент обработки имеем уникаьных комментариев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70962"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tag'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим 5000 самых популярных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "mc = Counter(data['tag']).most_common(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_to_del = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если уникальных блоков кода с этим комментарием меньше 75, то удалим эту метку т.к. это скорее всего скопированный комментарий. Этот процесс проводится среди самых популярных 5000 тэгов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:37<00:00, 133.94it/s]\n"
     ]
    }
   ],
   "source": [
    "for el in tqdm(mc):\n",
    "    if data[data['tag']==el[0]]['code_block'].nunique() < 75:\n",
    "        strange_to_del.append(el[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4904/4904 [01:25<00:00, 57.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for el in tqdm(strange_to_del):\n",
    "    data = data[data['tag'] != el]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь теряется некоторое количество данных и остается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118655, 2)\n",
      "66058\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data['tag'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на самые популярные 20 меток:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('specify_none_want_read_whole_fil', 2403),\n",
       " ('linear_algebra', 1859),\n",
       " ('model', 1223),\n",
       " ('check_answ', 714),\n",
       " ('predict', 683),\n",
       " ('train', 610),\n",
       " ('load_data', 518),\n",
       " ('plot', 505),\n",
       " ('visual', 493),\n",
       " ('preprocess', 458),\n",
       " ('code', 430),\n",
       " ('submiss', 405),\n",
       " ('feature_engin', 400),\n",
       " ('test', 393),\n",
       " ('random_forest', 391),\n",
       " ('eda', 342),\n",
       " ('import', 340),\n",
       " ('data_preprocess', 318),\n",
       " ('data_clean', 304),\n",
       " ('xgboost', 290)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data['tag']).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66038"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tags_to_drop = data['tag'].nunique() - 20\n",
    "num_tags_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление самых непопулярные (nunique - 20) меток:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_c_tags = set(Counter(data['tag']).most_common()[-num_tags_to_drop:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66038/66038 [10:27<00:00, 105.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for el in tqdm(least_c_tags):\n",
    "    data = data[data['tag'] != el[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13079, 2)\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data['tag'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_data = \\\n",
    "data.reset_index().drop(columns=['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = Counter(ready_data['tag']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"most_common_50_1.txt\", 'w') as output:\n",
    "#    for row in mc:\n",
    "#        output.write(str(row) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе метки вышли не самыми лучшими, поэтому давайте попробуем доработать их самостоятельно:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Вариант для стемминга (финальный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['plot', 'linear_algebra', 'model', 'check_answ', 'feature_engin',\n",
       "       'submiss', 'preprocess', 'load_data', 'train', 'random_forest',\n",
       "       'eda', 'predict', 'data_preprocess', 'xgboost', 'data_clean',\n",
       "       'test', 'specify_none_want_read_whole_fil', 'code', 'import',\n",
       "       'visual'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_data['tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "jut_inds = ready_data[ready_data['tag'] == 'specify_none_want_read_whole_fil'].index\n",
    "ready_data.drop(index=jut_inds, axis=0, inplace=True)\n",
    "jut_inds = ready_data[ready_data['tag'] == 'create_x'].index\n",
    "ready_data.drop(index=jut_inds, axis=0, inplace=True)\n",
    "jut_inds = ready_data[ready_data['tag'] == 'uncom'].index\n",
    "ready_data.drop(index=jut_inds, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "ready_data.loc[ready_data['tag'] == 'data_preprocessing', 'tag'] = 'preprocessing'\n",
    "ready_data.loc[ready_data['tag'] == 'data_load', 'tag'] = 'load_data'\n",
    "ready_data.loc[ready_data['tag'] == 'data', 'tag'] = 'load_data'\n",
    "ready_data.loc[ready_data['tag'] == 'importing_data', 'tag'] = 'load_data'\n",
    "ready_data.loc[ready_data['tag'] == 'reading_data', 'tag'] = 'load_data'\n",
    "ready_data.loc[ready_data['tag'] == 'eda', 'tag'] = 'exploratory_data_analysi'\n",
    "ready_data.loc[ready_data['tag'] == 'data_explor', 'tag'] = 'exploratory_data_analysi'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "jut_inds = ready_data[ready_data['tag'] == 'code'].index\n",
    "ready_data.drop(index=jut_inds, axis=0, inplace=True)\n",
    "jut_inds = ready_data[ready_data['tag'] == '1'].index\n",
    "ready_data.drop(index=jut_inds, axis=0, inplace=True)\n",
    "\n",
    "ready_data.loc[ready_data['tag'] == 'importing_librari', 'tag'] = 'import_librari'\n",
    "ready_data.loc[ready_data['tag'] == 'import', 'tag'] = 'import_librari'\n",
    "ready_data.loc[ready_data['tag'] == 'librari', 'tag'] = 'import_librari'\n",
    "ready_data.loc[ready_data['tag'] == 'training_model', 'tag'] = 'import_librari'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Вариант без стемминга, без лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready_data.loc[ready_data['tag'] == 'data_preprocessing', 'tag'] = 'preprocessing'\n",
    "#ready_data.loc[ready_data['tag'] == 'modelling', 'tag'] = '\n",
    "#ready_data.loc[ready_data['tag'] == 'model_building', 'tag'] = 'model_building'\n",
    "#ready_data.loc[ready_data['tag'] == 'data_visualization', 'tag'] = 'visualization'\n",
    "#ready_data.loc[ready_data['tag'] == 'data', 'tag'] = 'load_data'\n",
    "#ready_data.loc[ready_data['tag'] == 'exploratory_data_analysis', 'tag'] = 'eda'\n",
    "#ready_data.loc[ready_data['tag'] == 'training', 'tag'] = 'train'\n",
    "\n",
    "#jut_inds = ready_data[ready_data['tag'] == 'just_uncomment_them'].index\n",
    "#ready_data.drop(index=jut_inds, axis=0, inplace=True)\n",
    "#jut_inds = ready_data[ready_data['tag'] == 'check_your_answer'].index\n",
    "#ready_data.drop(index=jut_inds, axis=0, inplace=True)\n",
    "#jut_inds = ready_data[ready_data['tag'] == 'check_your_answers'].index\n",
    "#ready_data.drop(index=jut_inds, axis=0, inplace=True)\n",
    "#jut_inds = ready_data[ready_data['tag'] == 'your_code_here'].index\n",
    "#ready_data.drop(index=jut_inds, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Вариант с использованием только лемматизации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready_data.loc[ready_data['tag'] == 'check_your_answers', 'tag'] = 'check_your_answer'\n",
    "#ready_data.loc[ready_data['tag'] == 'data_preprocessing', 'tag'] = 'preprocessing'\n",
    "#ready_data.loc[ready_data['tag'] == 'training', 'tag'] = 'train'\n",
    "#ready_data.loc[ready_data['tag'] == 'exploratory_data_analysis', 'tag'] = 'eda'\n",
    "#ready_data.loc[ready_data['tag'] == 'data', 'tag'] = 'load_data'\n",
    "#ready_data.loc[ready_data['tag'] == 'model_building', 'tag'] = 'model'\n",
    "\n",
    "#jut_inds = ready_data[ready_data['tag'] == 'just_uncomment_them'].index\n",
    "#ready_data.drop(index=jut_inds, axis=0, inplace=True)\n",
    "#jut_inds = ready_data[ready_data['tag'] == 'your_code_here'].index\n",
    "#ready_data.drop(index=jut_inds, axis=0, inplace=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант для стемминга:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready_data.loc[ready_data['tag'] == 'data', 'tag'] = 'load_data'\n",
    "#ready_data.loc[ready_data['tag'] == 'train_model', 'tag'] = 'train'\n",
    "#ready_data.loc[ready_data['tag'] == 'fit_model', 'tag'] = 'train'\n",
    "#ready_data.loc[ready_data['tag'] == 'data_preprocess', 'tag'] = 'preprocess'\n",
    "#ready_data.loc[ready_data['tag'] == 'check_answers', 'tag'] = 'check_answer'\n",
    "#ready_data.loc[ready_data['tag'] == 'model', 'tag'] = 'model_building'\n",
    "#ready_data.loc[ready_data['tag'] == 'data_visu', 'tag'] = 'visual'\n",
    "#ready_data.loc[ready_data['tag'] == 'model_building', 'tag'] = 'model_build'\n",
    "\n",
    "#jut_inds = ready_data[ready_data['tag'] == 'uncomment_them'].index\n",
    "#ready_data.drop(index=jut_inds, axis=0, inplace=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10246, 2)\n",
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('linear_algebra', 1859),\n",
       " ('model', 1223),\n",
       " ('check_answ', 714),\n",
       " ('predict', 683),\n",
       " ('train', 610),\n",
       " ('load_data', 518),\n",
       " ('plot', 505),\n",
       " ('visual', 493),\n",
       " ('preprocess', 458),\n",
       " ('submiss', 405),\n",
       " ('feature_engin', 400),\n",
       " ('test', 393),\n",
       " ('random_forest', 391),\n",
       " ('exploratory_data_analysi', 342),\n",
       " ('import_librari', 340),\n",
       " ('data_preprocess', 318),\n",
       " ('data_clean', 304),\n",
       " ('xgboost', 290)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ready_data.shape)\n",
    "print(ready_data['tag'].nunique())\n",
    "Counter(ready_data['tag']).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Восстановление баланса классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "todel_mc1 = np.random.choice(\n",
    "    np.array(ready_data[ready_data['tag'] == 'linear_algebra'].index),\n",
    "    1859 - 1200,\n",
    "    replace = False\n",
    ")\n",
    "\n",
    "ready_data.drop(index=todel_mc1, inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9587, 2)\n",
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('model', 1223),\n",
       " ('linear_algebra', 1200),\n",
       " ('check_answ', 714),\n",
       " ('predict', 683),\n",
       " ('train', 610),\n",
       " ('load_data', 518),\n",
       " ('plot', 505),\n",
       " ('visual', 493),\n",
       " ('preprocess', 458),\n",
       " ('submiss', 405),\n",
       " ('feature_engin', 400),\n",
       " ('test', 393),\n",
       " ('random_forest', 391),\n",
       " ('exploratory_data_analysi', 342),\n",
       " ('import_librari', 340),\n",
       " ('data_preprocess', 318),\n",
       " ('data_clean', 304),\n",
       " ('xgboost', 290)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ready_data.shape)\n",
    "print(ready_data['tag'].nunique())\n",
    "Counter(ready_data['tag']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "jut_inds = ready_data[ready_data['tag'] == 'check_answ'].index\n",
    "ready_data.drop(index=jut_inds, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8873, 2)\n",
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('model', 1223),\n",
       " ('linear_algebra', 1200),\n",
       " ('predict', 683),\n",
       " ('train', 610),\n",
       " ('load_data', 518),\n",
       " ('plot', 505),\n",
       " ('visual', 493),\n",
       " ('preprocess', 458),\n",
       " ('submiss', 405),\n",
       " ('feature_engin', 400),\n",
       " ('test', 393),\n",
       " ('random_forest', 391),\n",
       " ('exploratory_data_analysi', 342),\n",
       " ('import_librari', 340),\n",
       " ('data_preprocess', 318),\n",
       " ('data_clean', 304),\n",
       " ('xgboost', 290)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ready_data.shape)\n",
    "print(ready_data['tag'].nunique())\n",
    "Counter(ready_data['tag']).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим на train, test, val в соотношении 8.5 / 1.5 / 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделим нацело:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "804.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ready_data.shape[0] - 7) / 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_data = ready_data.drop(ready_data.tail(7).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть размер обучающей выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6432.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_data.shape[0] / 11 * 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение на train, test, validation с помощью StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "SEED = 42001\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=3/11, random_state=SEED)\n",
    "for train_index, test_valid_index in split.split(\\\n",
    "                                                 ready_data.drop('tag', axis=1), \\\n",
    "                                                 ready_data['tag']\\\n",
    "                                                ):\n",
    "    train_set = ready_data.iloc[train_index]\n",
    "    test_valid_set = ready_data.iloc[test_valid_index]\n",
    "\n",
    "split2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=SEED)\n",
    "for test_index, valid_index in split2.split(test_valid_set, test_valid_set['tag']):\n",
    "    test_set = test_valid_set.iloc[test_index]\n",
    "    valid_set = test_valid_set.iloc[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.reset_index()\n",
    "test_set = test_set.reset_index()\n",
    "valid_set = valid_set.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее все '\\n' заменяются на '\\n\\t', а также вначале каждого сниппета приписывается\n",
    "\n",
    "'def tag():\\n\\t'\n",
    "\n",
    "Каждый сниппет записывается в **отдельный файл** с названием номер_итерации.py в каталог my_train, my_test или my_valid (требование к формату code2vec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tabs(exmpl):\n",
    "    new_exmpl = str()\n",
    "    for i in range(len(exmpl)):\n",
    "        if (exmpl[i]=='\\n'):\n",
    "            new_exmpl += '\\n\\t'\n",
    "        else:\n",
    "            new_exmpl += exmpl[i]\n",
    "    return new_exmpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_set.shape[0]):\n",
    "        exmpl = train_set.loc[i]['code_block'][:-1]\n",
    "        exmpl = add_tabs(exmpl)\n",
    "        print('def ' + str(train_set.loc[i]['tag'])+'():\\n\\t' + exmpl\n",
    "              ,  file=open('/home/kirill/code2vec/cd2vec/python/my_train/func'+str(i)+'.py', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_set.shape[0]):\n",
    "        exmpl = test_set.loc[i]['code_block'][:-1]\n",
    "        exmpl = add_tabs(exmpl)\n",
    "        print('def ' + str(test_set.loc[i]['tag'])+'():\\n\\t' + exmpl\n",
    "              ,  file=open('/home/kirill/code2vec/cd2vec/python/my_test/func'+str(i)+'.py', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(valid_set.shape[0]):\n",
    "        exmpl = valid_set.loc[i]['code_block'][:-1]\n",
    "        exmpl = add_tabs(exmpl)\n",
    "        print('def ' + str(valid_set.loc[i]['tag'])+'():\\n\\t' + exmpl\n",
    "              ,  file=open('/home/kirill/code2vec/cd2vec/python/my_val/func'+str(i)+'.py', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
