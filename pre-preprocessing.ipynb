{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_block</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nimport pandas as pd\\nimport matplotlib.pyplo...</td>\n",
       "      <td>['invite people for the kaggle party']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\ndf_train = pd.read_csv('../input/train.csv'),</td>\n",
       "      <td>['bring in the six packs']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ndf_train.columns,</td>\n",
       "      <td>['check the decoration']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\ndf_train['SalePrice'].describe(),</td>\n",
       "      <td>['descriptive statistics summary']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nsns.distplot(df_train['SalePrice']);,</td>\n",
       "      <td>['histogram']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          code_block  \\\n",
       "0  \\nimport pandas as pd\\nimport matplotlib.pyplo...   \n",
       "1    \\ndf_train = pd.read_csv('../input/train.csv'),   \n",
       "2                                \\ndf_train.columns,   \n",
       "3                \\ndf_train['SalePrice'].describe(),   \n",
       "4            \\nsns.distplot(df_train['SalePrice']);,   \n",
       "\n",
       "                                      tag  \n",
       "0  ['invite people for the kaggle party']  \n",
       "1              ['bring in the six packs']  \n",
       "2                ['check the decoration']  \n",
       "3      ['descriptive statistics summary']  \n",
       "4                           ['histogram']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/kirill/Desktop/code_blocks_big.csv', sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уникальных тегов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102123"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tag'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213535,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tag'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление стоп-слов, стемминг, оставляем по одному комментарию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import download\n",
    "# download('stopwords')\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_wr = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_str = 'kirill eats grass on the floors, long word endings, churches'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lemmatizer thx to \n",
    "\n",
    "https://medium.com/@gaurav5430/using-nltk-for-lemmatizing-sentences-c1bfff963258 \n",
    "\n",
    "(left a clap):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kirill eat grass on the floor , long word ending , church'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(lemmatizer, sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "lemmatize_sentence(wnl, ex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kirill eats grass on the floors, long word endings, church'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "stemmer.stem(ex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно:** если у вас в табличке есть колонка 'Unnamed 0:' или вообще какая то лишняя, то дропайте ее до этого цикла (почему-то это сильно влияет на производительность)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут из нескольких комментариев выбирается самый короткий (обосновано тем, что тогда он с большей вероятностью встречается часто ака больше похож на метку). Отсекаются пробелы и всякие пустые метки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clear_tag(tag):\n",
    "    ready_tag = tag.replace('_', ' ')\n",
    "    ready_tag = re.sub('[^A-Za-z0-9 ]+', '', ready_tag)\n",
    "    ready_tag = ready_tag.strip()                    # removes spaces in the start and in the end\n",
    "    ready_tag = ready_tag.replace(' ', '_')\n",
    "    return ready_tag # replace spaces with \"_\" and removes other punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "all_to_del = set(['', \"['']\", ' ', '  ', \"[' ']\", '        ', '     ', '    ', '   ', \"['', ' ']\", '       ', '      ', \\\n",
    "             '             ', '         ', '          ', \"']\",\\\n",
    "                 \"['   \", \"['\", \"[' \", \"['  \", \"['    \", \"['    \"])\n",
    "rows_to_del = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213535/213535 [02:43<00:00, 1308.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(data.shape[0])):\n",
    "    my_string = data.loc[i, 'tag']\n",
    "    \n",
    "    if (my_string is not np.nan) and my_string is not None:\n",
    "        \n",
    "        min_len = len(data.loc[i, 'tag']) + 10\n",
    "        min_el = None\n",
    "        s = set(list(map(str, my_string.split(\"', '\"))))\n",
    "        \n",
    "        for el in s:\n",
    "            \n",
    "            # getting rid of punctuation, spaces, adding \"_\"\n",
    "            el = clear_tag(el)\n",
    "            \n",
    "            if el not in all_to_del and el is not None and len(el) < 100:\n",
    "                \n",
    "                # getting rid of stop words\n",
    "                el = [w.lower() for w in el.split() if w.lower() not in st_wr]\n",
    "                el = ' '.join(el)\n",
    "                \n",
    "                # stemming \n",
    "                #el = stemmer.stem(el)\n",
    "                \n",
    "                # lemmatizing\n",
    "                el = lemmatize_sentence(wnl, el)\n",
    "                \n",
    "                if len(el) < min_len:\n",
    "                    min_len = len(el)\n",
    "                    min_el = el\n",
    "\n",
    "        if min_el is not None:\n",
    "            data.loc[i, 'tag'] = min_el\n",
    "        else:\n",
    "            rows_to_del.append(i)\n",
    "    else:\n",
    "        rows_to_del.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213535, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(rows_to_del)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174210, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_block</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nimport pandas as pd\\nimport matplotlib.pyplo...</td>\n",
       "      <td>invite_people_for_the_kaggle_party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\ndf_train = pd.read_csv('../input/train.csv'),</td>\n",
       "      <td>bring_in_the_six_packs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ndf_train.columns,</td>\n",
       "      <td>check_the_decoration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\ndf_train['SalePrice'].describe(),</td>\n",
       "      <td>descriptive_statistics_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nsns.distplot(df_train['SalePrice']);,</td>\n",
       "      <td>histogram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          code_block  \\\n",
       "0  \\nimport pandas as pd\\nimport matplotlib.pyplo...   \n",
       "1    \\ndf_train = pd.read_csv('../input/train.csv'),   \n",
       "2                                \\ndf_train.columns,   \n",
       "3                \\ndf_train['SalePrice'].describe(),   \n",
       "4            \\nsns.distplot(df_train['SalePrice']);,   \n",
       "\n",
       "                                  tag  \n",
       "0  invite_people_for_the_kaggle_party  \n",
       "1              bring_in_the_six_packs  \n",
       "2                check_the_decoration  \n",
       "3      descriptive_statistics_summary  \n",
       "4                           histogram  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=['index'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['tag'] != '']\n",
    "data = data[data['tag'] != '_']\n",
    "data = data[data['tag'] != '__']\n",
    "data = data[data['tag'] != '___']\n",
    "data = data[data['tag'] != '____']\n",
    "data = data[data['tag'] != '_____']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось уже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174009, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Режем по длинне метки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь проверка, чтобы не было копипаста, потому что комментарий длиннее 30 символов совпавший так много раз явно коппаст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['tag'].str.len() < 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111737, 2)\n",
      "31190\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data['tag'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оставим какие-то самые популярные метки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из самых популярных 5к меток выкину варианты длиннее n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31190"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tag'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "mc = Counter(data['tag']).most_common(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_to_del = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это работает не очень "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если уникальных блоков кода с этим комментарием меньше 75 (естественно стоит эту константу пробовать менять), то удалим эту метку тк это скорее всего копипаст:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так делаем среди самых популярных 5к тегов чтобы не тратить время на совсем не популярные метки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:08<00:00, 73.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for el in tqdm(mc):\n",
    "    if data[data['tag']==el[0]]['code_block'].nunique() < 75:\n",
    "        strange_to_del.append(el[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4935/4935 [01:50<00:00, 44.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for el in tqdm(strange_to_del):\n",
    "    data = data[data['tag'] != el]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь естественно теряется много данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54430, 2)\n",
      "26255\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data['tag'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что выкинули 4940 меток из самых популярных 5000, оставим 30 самых популярных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linear_algebra', 3130),\n",
       " ('plot', 2955),\n",
       " ('model', 974),\n",
       " ('check_your_answer', 608),\n",
       " ('create_x', 558),\n",
       " ('your_code_here', 466),\n",
       " ('preprocessing', 437),\n",
       " ('feature_engineering', 428),\n",
       " ('just_uncomment_them', 402),\n",
       " ('prediction', 400),\n",
       " ('load_data', 385),\n",
       " ('submission', 380),\n",
       " ('check_your_answers', 353),\n",
       " ('random_forest', 342),\n",
       " ('data_preprocessing', 306),\n",
       " ('training', 277),\n",
       " ('test', 272),\n",
       " ('visualization', 270),\n",
       " ('import', 269),\n",
       " ('eda', 257),\n",
       " ('predict', 255),\n",
       " ('data', 219),\n",
       " ('train', 207),\n",
       " ('data_cleaning', 203),\n",
       " ('input', 201),\n",
       " ('logistic_regression', 200),\n",
       " ('model_building', 191),\n",
       " ('xgboost', 184),\n",
       " ('exploratory_data_analysis', 184),\n",
       " ('data_visualization', 184)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data['tag']).most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_to_del - задан вначале ноутбука"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for to_del in all_to_del:\n",
    "    data = data[data['tag'] != to_del]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54430, 2)\n",
      "26255\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data['tag'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26225"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tags_to_drop = data['tag'].nunique() - 30\n",
    "num_tags_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выкидываю самые непопулярные (nunique - 30) меток:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_c_tags = set(Counter(data['tag']).most_common()[-num_tags_to_drop:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26225/26225 [06:18<00:00, 69.23it/s] \n"
     ]
    }
   ],
   "source": [
    "for el in tqdm(least_c_tags):\n",
    "    data = data[data['tag'] != el[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим что осталось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15382, 2)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data['tag'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_data = \\\n",
    "data.reset_index().drop(columns=['index'], axis=1)\n",
    "#ready_data = ready_data.drop(columns=['level_0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linear_algebra', 3130),\n",
       " ('plot', 2955),\n",
       " ('model', 974),\n",
       " ('check_your_answer', 608),\n",
       " ('create_x', 558),\n",
       " ('your_code_here', 466),\n",
       " ('preprocessing', 437),\n",
       " ('feature_engineering', 428),\n",
       " ('just_uncomment_them', 402),\n",
       " ('prediction', 400)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(ready_data['tag']).most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('predict', 255),\n",
       " ('data', 219),\n",
       " ('train', 207),\n",
       " ('data_cleaning', 203),\n",
       " ('input', 201),\n",
       " ('logistic_regression', 200),\n",
       " ('model_building', 191),\n",
       " ('xgboost', 184),\n",
       " ('exploratory_data_analysis', 184),\n",
       " ('data_visualization', 184)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(ready_data['tag']).most_common()[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе все работает очень плохо, поэтому давайте попробуем руками с метками поработать..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['visualization', 'logistic_regression', 'random_forest',\n",
       "       'linear_algebra', 'plot', 'load_data', 'prediction', 'xgboost',\n",
       "       'import', 'preprocessing', 'model', 'predict', 'submission',\n",
       "       'data', 'training', 'feature_engineering',\n",
       "       'exploratory_data_analysis', 'train', 'test', 'input',\n",
       "       'data_visualization', 'data_cleaning', 'eda', 'check_your_answer',\n",
       "       'data_preprocessing', 'model_building', 'create_x',\n",
       "       'check_your_answers', 'your_code_here', 'just_uncomment_them'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_data['tag'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант для лемматизации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_data.loc[ready_data['tag'] == 'check_your_answers', 'tag'] = 'check_your_answer'\n",
    "ready_data.loc[ready_data['tag'] == 'data_preprocessing', 'tag'] = 'preprocessing'\n",
    "ready_data.loc[ready_data['tag'] == 'training', 'tag'] = 'train'\n",
    "ready_data.loc[ready_data['tag'] == 'exploratory_data_analysis', 'tag'] = 'eda'\n",
    "ready_data.loc[ready_data['tag'] == 'data', 'tag'] = 'load_data'\n",
    "ready_data.loc[ready_data['tag'] == 'model_building', 'tag'] = 'model'\n",
    "\n",
    "\n",
    "jut_inds = ready_data[ready_data['tag'] == 'just_uncomment_them'].index\n",
    "ready_data.drop(index=jut_inds, axis=0, inplace=True)\n",
    "jut_inds = ready_data[ready_data['tag'] == 'your_code_here'].index\n",
    "ready_data.drop(index=jut_inds, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант для стемминга:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, train_model, model_build, model, fit_model\n",
    "# train_model, fit_model -> train\n",
    "# 'data_visu' -> visual\n",
    "# model_building -> model_build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_data.loc[ready_data['tag'] == 'data', 'tag'] = 'load_data'\n",
    "ready_data.loc[ready_data['tag'] == 'train_model', 'tag'] = 'train'\n",
    "ready_data.loc[ready_data['tag'] == 'fit_model', 'tag'] = 'train'\n",
    "ready_data.loc[ready_data['tag'] == 'data_preprocess', 'tag'] = 'preprocess'\n",
    "ready_data.loc[ready_data['tag'] == 'check_answers', 'tag'] = 'check_answer'\n",
    "ready_data.loc[ready_data['tag'] == 'model', 'tag'] = 'model_building'\n",
    "ready_data.loc[ready_data['tag'] == 'data_visu', 'tag'] = 'visual'\n",
    "ready_data.loc[ready_data['tag'] == 'model_building', 'tag'] = 'model_build'\n",
    "\n",
    "jut_inds = ready_data[ready_data['tag'] == 'uncomment_them'].index\n",
    "ready_data.drop(index=jut_inds, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без всего:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data -> load_data\n",
    "# exploratory_data_analysis, data_exploration -> eda\n",
    "# data_preprocessing -> preprocessing\n",
    "# training -> train\n",
    "# check_your_answer, check_your_answers -> check_answer\n",
    "# model -> model_building\n",
    "# just_uncomment_them -> trash\n",
    "\n",
    "\n",
    "##################### maybe\n",
    "# prediction - test ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ready_data.loc[ready_data['tag'] == 'data', 'tag'] = 'load_data'\\nready_data.loc[ready_data['tag'] == 'exploratory_data_analysis', 'tag'] = 'eda'\\nready_data.loc[ready_data['tag'] == 'data_exploration', 'tag'] = 'eda'\\nready_data.loc[ready_data['tag'] == 'data_preprocessing', 'tag'] = 'preprocessing'\\nready_data.loc[ready_data['tag'] == 'training', 'tag'] = 'train'\\nready_data.loc[ready_data['tag'] == 'check_your_answer', 'tag'] = 'check_answer'\\nready_data.loc[ready_data['tag'] == 'check_your_answers', 'tag'] = 'check_answer'\\nready_data.loc[ready_data['tag'] == 'model', 'tag'] = 'model_building'\\n\\njut_inds = ready_data[ready_data['tag'] == 'just_uncomment_them'].index\\nready_data.drop(index=jut_inds, axis=0, inplace=True)\""
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ready_data.loc[ready_data['tag'] == 'data', 'tag'] = 'load_data'\n",
    "ready_data.loc[ready_data['tag'] == 'exploratory_data_analysis', 'tag'] = 'eda'\n",
    "ready_data.loc[ready_data['tag'] == 'data_exploration', 'tag'] = 'eda'\n",
    "ready_data.loc[ready_data['tag'] == 'data_preprocessing', 'tag'] = 'preprocessing'\n",
    "ready_data.loc[ready_data['tag'] == 'training', 'tag'] = 'train'\n",
    "ready_data.loc[ready_data['tag'] == 'check_your_answer', 'tag'] = 'check_answer'\n",
    "ready_data.loc[ready_data['tag'] == 'check_your_answers', 'tag'] = 'check_answer'\n",
    "ready_data.loc[ready_data['tag'] == 'model', 'tag'] = 'model_building'\n",
    "\n",
    "jut_inds = ready_data[ready_data['tag'] == 'just_uncomment_them'].index\n",
    "ready_data.drop(index=jut_inds, axis=0, inplace=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14629, 2)\n",
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('linear_algebra', 3130),\n",
       " ('plot', 2955),\n",
       " ('model', 1165),\n",
       " ('check_your_answer', 961),\n",
       " ('preprocessing', 743),\n",
       " ('load_data', 604),\n",
       " ('create_x', 558),\n",
       " ('train', 484),\n",
       " ('eda', 441),\n",
       " ('feature_engineering', 428),\n",
       " ('prediction', 400),\n",
       " ('submission', 380),\n",
       " ('random_forest', 342),\n",
       " ('test', 272),\n",
       " ('visualization', 270),\n",
       " ('import', 269),\n",
       " ('predict', 255),\n",
       " ('data_cleaning', 203),\n",
       " ('input', 201),\n",
       " ('logistic_regression', 200),\n",
       " ('xgboost', 184),\n",
       " ('data_visualization', 184)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ready_data.shape)\n",
    "print(ready_data['tag'].nunique())\n",
    "Counter(ready_data['tag']).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слишком много линейной алгебры и др, давайте из них выберем по 800 объектов (не костыль, а эксперимент)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем unbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "todel_mc1 = np.random.choice(\n",
    "    np.array(ready_data[ready_data['tag'] == 'linear_algebra'].index),\n",
    "    3130 - 1000,\n",
    "    replace = False\n",
    ")\n",
    "todel_mc2 = np.random.choice(\n",
    "    np.array(ready_data[ready_data['tag'] == 'plot'].index),\n",
    "    2955 - 1000,\n",
    "    replace = False\n",
    ")\n",
    "\n",
    "ready_data.drop(index=todel_mc1, inplace=True, axis=0)\n",
    "ready_data.drop(index=todel_mc2, inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10210, 2)\n",
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('linear_algebra', 1000),\n",
       " ('model', 1000),\n",
       " ('check_your_answer', 961),\n",
       " ('plot', 831),\n",
       " ('preprocessing', 743),\n",
       " ('load_data', 604),\n",
       " ('create_x', 558),\n",
       " ('train', 484),\n",
       " ('eda', 441),\n",
       " ('feature_engineering', 428),\n",
       " ('prediction', 400),\n",
       " ('submission', 380),\n",
       " ('random_forest', 342),\n",
       " ('test', 272),\n",
       " ('visualization', 270),\n",
       " ('import', 269),\n",
       " ('predict', 255),\n",
       " ('data_cleaning', 203),\n",
       " ('input', 201),\n",
       " ('logistic_regression', 200),\n",
       " ('xgboost', 184),\n",
       " ('data_visualization', 184)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ready_data.shape)\n",
    "print(ready_data['tag'].nunique())\n",
    "Counter(ready_data['tag']).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соотношения train, test, val = 8.5 / 1.5 / 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделим нацело:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ready_data.shape[0] - 2) / 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_data = ready_data.drop(ready_data.tail(2).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_data.shape[0] / 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть размер трейна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7424.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "928.0 * 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стратифайдом делю на трейн, тест, сплит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/40829137/stratified-train-validation-test-split-in-scikit-learn\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "SEED = 42001\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=3/11, random_state=SEED)\n",
    "for train_index, test_valid_index in split.split(\\\n",
    "                                                 ready_data.drop('tag', axis=1), \\\n",
    "                                                 ready_data['tag']\\\n",
    "                                                ):\n",
    "    train_set = ready_data.iloc[train_index]\n",
    "    test_valid_set = ready_data.iloc[test_valid_index]\n",
    "\n",
    "split2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=SEED)\n",
    "for test_index, valid_index in split2.split(test_valid_set, test_valid_set['tag']):\n",
    "    test_set = test_valid_set.iloc[test_index]\n",
    "    valid_set = test_valid_set.iloc[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.reset_index()\n",
    "test_set = test_set.reset_index()\n",
    "valid_set = valid_set.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее все '\\n' заменяются на '\\n\\t', а также вначале каждого сниппета приписывается\n",
    "\n",
    "'def tag():\\n\\t'\n",
    "\n",
    "Каждый сниппет записывается в **отдельный файл** с названием номер_итерации.py в каталог трей, тест или валидейшн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tabs(exmpl):\n",
    "    new_exmpl = str()\n",
    "    for i in range(len(exmpl)):\n",
    "        if (exmpl[i]=='\\n'):\n",
    "            new_exmpl += '\\n\\t'\n",
    "        else:\n",
    "            new_exmpl += exmpl[i]\n",
    "    return new_exmpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_set.shape[0]):\n",
    "        exmpl = train_set.loc[i]['code_block'][:-1]\n",
    "        exmpl = add_tabs(exmpl)\n",
    "        print('def ' + str(train_set.loc[i]['tag'])+'():\\n\\t' + exmpl\n",
    "              ,  file=open('/home/kirill/code2vec/cd2vec/python/my_train/func'+str(i)+'.py', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_set.shape[0]):\n",
    "        exmpl = test_set.loc[i]['code_block'][:-1]\n",
    "        exmpl = add_tabs(exmpl)\n",
    "        print('def ' + str(test_set.loc[i]['tag'])+'():\\n\\t' + exmpl\n",
    "              ,  file=open('/home/kirill/code2vec/cd2vec/python/my_test/func'+str(i)+'.py', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(valid_set.shape[0]):\n",
    "        exmpl = valid_set.loc[i]['code_block'][:-1]\n",
    "        exmpl = add_tabs(exmpl)\n",
    "        print('def ' + str(valid_set.loc[i]['tag'])+'():\\n\\t' + exmpl\n",
    "              ,  file=open('/home/kirill/code2vec/cd2vec/python/my_val/func'+str(i)+'.py', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1392"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка для просто 30 строк кода посложнее, пока ее нет."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
